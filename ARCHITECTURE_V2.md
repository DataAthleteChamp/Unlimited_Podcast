# Endless AI Podcast - Professional Architecture (V2)

## ğŸ¯ Executive Summary

**Project:** Endless AI Podcast - Interactive, never-ending AI podcast with community engagement
**Stack:** Python (FastAPI) + React (Vite/Lovable) + Multi-LLM Orchestration
**Timeline:** Hackathon day (9:30 AM - 5:00 PM)
**Target:** Production-quality demo with professional structure

---

## ğŸ§  Multi-LLM Architecture

### LLM Role Distribution

Based on research into supervisor/orchestrator patterns and multi-agent systems, we'll use:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SUPERVISOR (GPT-4o)                         â”‚
â”‚  â€¢ Topic selection with weighted reactions              â”‚
â”‚  â€¢ Content orchestration                                â”‚
â”‚  â€¢ Turn coordination                                    â”‚
â”‚  â€¢ Quality control                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                â”‚
         â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  CONTENT GENERATOR  â”‚         â”‚   CHAT AGENTS (3x)   â”‚
â”‚    (GPT-4o-mini)    â”‚         â”‚   (GPT-4o-mini)      â”‚
â”‚                     â”‚         â”‚                      â”‚
â”‚ Generates full      â”‚         â”‚ Persona 1: Enthusiastâ”‚
â”‚ dialogue script:    â”‚         â”‚ Persona 2: Skeptic   â”‚
â”‚ Alex: "..."         â”‚         â”‚ Persona 3: Curious   â”‚
â”‚ Mira: "..."         â”‚         â”‚                      â”‚
â”‚                     â”‚         â”‚ Generate community   â”‚
â”‚ Includes context,   â”‚         â”‚ chat comments        â”‚
â”‚ transitions, tone   â”‚         â”‚                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               SPEECH SYNTHESIS (OpenAI TTS)              â”‚
â”‚  Voice 1: "alloy" â†’ Alex (optimistic)                    â”‚
â”‚  Voice 2: "onyx"  â†’ Mira (skeptical)                     â”‚
â”‚  Parse script, generate separate audio segments          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Why This Architecture?

1. **Supervisor Pattern**: One "brain" coordinates all decisions (research: Anthropic multi-agent system)
2. **Separation of Concerns**: Text generation separate from TTS (best practice)
3. **Cost Efficiency**: GPT-4o-mini for heavy workloads, GPT-4o for critical decisions
4. **Scalability**: Easy to add more chat agents or features

---

## ğŸ—ï¸ System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                FRONTEND (React + Vite)                     â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Topic Input â”‚  â”‚ Live Podcast â”‚  â”‚  Community Chat â”‚  â”‚
â”‚  â”‚ + Voting    â”‚  â”‚   Player     â”‚  â”‚  (AI + Users)   â”‚  â”‚
â”‚  â”‚ + Reactions â”‚  â”‚ + Transcript â”‚  â”‚  + Nickname     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                            â”‚
â”‚  Features: Emoji reactions ğŸ‘ğŸ‘, Nickname input,           â”‚
â”‚            Real-time transcription, Audio player           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ HTTP + SSE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND (Python + FastAPI)                    â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ API Endpoints  â”‚  â”‚  Scheduler  â”‚  â”‚  SSE Manager   â”‚ â”‚
â”‚  â”‚ /topic /vote   â”‚  â”‚  (20s loop) â”‚  â”‚  (broadcast)   â”‚ â”‚
â”‚  â”‚ /react /chat   â”‚  â”‚  + Sounds   â”‚  â”‚               â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  State Manager â”‚  â”‚  Supervisor â”‚  â”‚ Content Gen    â”‚ â”‚
â”‚  â”‚  (in-memory)   â”‚  â”‚  LLM Brain  â”‚  â”‚ LLM Worker     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Chat Agents   â”‚  â”‚  TTS Engine â”‚  â”‚ Audio Manager  â”‚ â”‚
â”‚  â”‚  (3 personas)  â”‚  â”‚  (OpenAI)   â”‚  â”‚ + Transitions  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚              â”‚
                       â–¼              â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   Dust   â”‚   â”‚  OpenAI  â”‚
                 â”‚   API    â”‚   â”‚   API    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Data Flow

### 1. User Interaction Flow
```
User submits topic
  â†’ FastAPI /api/topic
  â†’ Add to topics[] with metadata (timestamp, user_nickname)
  â†’ Broadcast SSE: TOPICS_UPDATED

User votes/reacts
  â†’ POST /api/vote (delta: +1/-1)
  â†’ POST /api/react (emoji: ğŸ‘/ğŸ‘)
  â†’ Update weighted score:
      score = votes + (reactions_positive * 5) - (reactions_negative * 3)
  â†’ Broadcast SSE: TOPICS_UPDATED
```

### 2. Podcast Generation Flow (20s Loop)
```
Every 20 seconds:
  1. SUPERVISOR selects topic
     â””â”€ Calculate weighted scores
     â””â”€ Consider reaction balance
     â””â”€ If ğŸ‘ > 70%: continue current topic
     â””â”€ Else: switch to top voted topic

  2. Play transition sound ğŸµ
     â””â”€ Load from /static/sounds/transition.mp3

  3. SUPERVISOR instructs CONTENT GENERATOR
     Input: {
       topic: "AI in Healthcare",
       previous_context: "Last discussed ethics...",
       alex_last_turn: "I think...",
       mira_last_turn: "But consider...",
       turn_number: 3
     }

  4. CONTENT GENERATOR creates dialogue
     Output: {
       alex_text: "This is fascinating because...",
       mira_text: "I appreciate that perspective, but...",
       transition: "natural_flow" | "topic_switch",
       summary: "Discussion focused on..."
     }

  5. TTS generates audio (parallel)
     â”œâ”€ Alex audio: OpenAI TTS (voice: alloy)
     â””â”€ Mira audio: OpenAI TTS (voice: onyx)

  6. Save audio + generate transcript
     â”œâ”€ /static/audio/{timestamp}_alex.mp3
     â”œâ”€ /static/audio/{timestamp}_mira.mp3
     â””â”€ Store transcript in state

  7. Broadcast SSE events
     â”œâ”€ NOW_PLAYING: {speaker, topic, audio_url}
     â”œâ”€ TRANSCRIPT_UPDATE: {speaker, text}
     â””â”€ AUDIO_READY: {url, duration}

  8. CHAT AGENTS generate community comments (async)
     â””â”€ 3 personas generate reactions
     â””â”€ Broadcast SSE: CHAT_MESSAGE
```

### 3. Community Chat Flow
```
CHAT AGENTS (running in background):
  Every 10-15 seconds (randomized):
    1. Select random persona (Enthusiast/Skeptic/Curious)
    2. Generate contextual comment based on:
       - Current podcast topic
       - Recent dialogue
       - Sentiment balance
    3. Broadcast SSE: CHAT_MESSAGE {
         nickname: "AI_Enthusiast_42",
         message: "Great point about privacy!",
         is_ai: true,
         timestamp: ...
       }

Human user sends chat:
  â†’ POST /api/chat {nickname, message}
  â†’ Broadcast SSE: CHAT_MESSAGE {is_ai: false}
```

---

## ğŸ¨ Enhanced Features

### 1. Transcription Display
- Real-time text display of what Alex/Mira are saying
- Scroll with audio playback
- Highlight current speaker

### 2. Transition Sounds
- Play 2-3s audio effect when switching topics
- Smooth fade-in/fade-out
- Visual indicator of transition

### 3. Nickname System
- Modal on first visit: "Enter your nickname"
- Store in localStorage
- Display in chat messages

### 4. Emoji Reaction Voting
- ğŸ‘ Thumbs up: +5 points to topic score
- ğŸ‘ Thumbs down: -3 points to topic score
- If current topic gets >70% ğŸ‘: stay on topic (extend)
- Visual feedback on reactions

### 5. Community Vibe (AI Chat)
- 3 AI personas with distinct personalities
- Generate comments every 10-15s
- Context-aware (mention specific points from dialogue)
- Mix of agreement, questions, skepticism
- Labeled as AI (transparency)

---

## ğŸ“ Professional Project Structure

```
Unlimited_Podcast/
â”œâ”€â”€ .env.example                 # Template for environment variables
â”œâ”€â”€ .env                         # Actual credentials (gitignored)
â”œâ”€â”€ .gitignore                   # Comprehensive ignore rules
â”œâ”€â”€ README.md                    # Professional setup guide
â”œâ”€â”€ ARCHITECTURE_V2.md           # This file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ pyproject.toml               # Modern Python project config
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                  # FastAPI app entry point
â”‚   â”œâ”€â”€ config.py                # Load .env, validate settings
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                  # Pydantic models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ topic.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â”œâ”€â”€ podcast.py
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                # Business logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ supervisor.py        # Supervisor LLM orchestrator
â”‚   â”‚   â”œâ”€â”€ content_generator.py # Content generation LLM
â”‚   â”‚   â”œâ”€â”€ chat_agents.py       # Community chat AI personas
â”‚   â”‚   â”œâ”€â”€ tts_service.py       # OpenAI TTS wrapper
â”‚   â”‚   â”œâ”€â”€ dust_client.py       # Dust API integration
â”‚   â”‚   â””â”€â”€ audio_manager.py     # Audio file management
â”‚   â”‚
â”‚   â”œâ”€â”€ core/                    # Core functionality
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ state.py             # In-memory state management
â”‚   â”‚   â”œâ”€â”€ scheduler.py         # 20s podcast loop
â”‚   â”‚   â”œâ”€â”€ sse.py               # SSE event broadcasting
â”‚   â”‚   â””â”€â”€ scoring.py           # Reaction-weighted scoring
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                     # API routes
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ topics.py            # Topic endpoints
â”‚   â”‚   â”œâ”€â”€ podcast.py           # Podcast control
â”‚   â”‚   â”œâ”€â”€ chat.py              # Chat endpoints
â”‚   â”‚   â”œâ”€â”€ reactions.py         # Reaction endpoints
â”‚   â”‚   â””â”€â”€ stream.py            # SSE endpoint
â”‚   â”‚
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ audio/               # Generated podcast audio
â”‚   â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ sounds/              # Transition sound effects
â”‚   â”‚       â”œâ”€â”€ transition_1.mp3
â”‚   â”‚       â””â”€â”€ transition_2.mp3
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py            # Structured logging
â”‚       â””â”€â”€ exceptions.py        # Custom exceptions
â”‚
â”œâ”€â”€ frontend/                    # Lovable-generated React + Vite
â”‚   â”œâ”€â”€ public/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ TopicInput.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TopicList.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ PodcastPlayer.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ Transcript.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ CommunityChat.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ NicknameModal.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ReactionButtons.tsx
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useSSE.ts
â”‚   â”‚   â”‚   â”œâ”€â”€ useAudio.ts
â”‚   â”‚   â”‚   â””â”€â”€ useNickname.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ api.ts           # Backend API client
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â””â”€â”€ tsconfig.json
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ API.md                   # API documentation
    â”œâ”€â”€ DEMO_SCRIPT.md           # 2-minute demo guide
    â””â”€â”€ SETUP.md                 # Development setup
```

---

## ğŸ”§ Environment Variables (.env)

```env
# ======================================
# OpenAI Configuration
# ======================================
OPENAI_API_KEY=sk-proj-...
OPENAI_ORG_ID=org-...                    # Optional

# Models
SUPERVISOR_MODEL=gpt-4o                  # Supervisor brain
CONTENT_MODEL=gpt-4o-mini                # Content generation
CHAT_AGENT_MODEL=gpt-4o-mini             # Community chat

# TTS Voices
VOICE_ALEX=alloy                         # Optimistic speaker
VOICE_MIRA=onyx                          # Skeptical speaker
TTS_MODEL=tts-1                          # or tts-1-hd for quality

# ======================================
# Dust Configuration
# ======================================
DUST_API_KEY=dust_...
DUST_WORKSPACE_ID=...
DUST_AGENT_SUPERVISOR_ID=...             # Supervisor agent
DUST_AGENT_CONTENT_ID=...                # Content generator agent

# ======================================
# Server Configuration
# ======================================
BACKEND_HOST=0.0.0.0
BACKEND_PORT=8000
FRONTEND_URL=http://localhost:5173
CORS_ORIGINS=http://localhost:5173,http://127.0.0.1:5173

# ======================================
# Feature Flags
# ======================================
ENABLE_CHAT_AGENTS=true                  # AI-generated chat
ENABLE_DUST=true                         # Use Dust or fallback to OpenAI
ENABLE_TRANSCRIPTION=true                # Real-time transcript
CHAT_AGENT_COUNT=3                       # Number of AI chat personas

# ======================================
# Podcast Configuration
# ======================================
PODCAST_TURN_DURATION=20                 # Seconds per turn
TRANSITION_SOUND_ENABLED=true
CHAT_AGENT_INTERVAL=15                   # Seconds between AI comments

# ======================================
# Scoring Configuration
# ======================================
VOTE_WEIGHT=1                            # Base vote value
THUMBS_UP_WEIGHT=5                       # ğŸ‘ reaction weight
THUMBS_DOWN_WEIGHT=-3                    # ğŸ‘ reaction weight
TOPIC_CONTINUATION_THRESHOLD=0.7         # 70% positive â†’ stay on topic

# ======================================
# Development
# ======================================
DEBUG=true
LOG_LEVEL=INFO                           # DEBUG, INFO, WARNING, ERROR
```

---

## ğŸ“ .gitignore (Comprehensive)

```gitignore
# Environment variables
.env
.env.local
.env.*.local

# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
venv/
ENV/
env/
.venv/
pip-log.txt
pip-delete-this-directory.txt
.pytest_cache/
.coverage
htmlcov/
*.egg-info/
dist/
build/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

# Generated audio files
backend/static/audio/*.mp3
backend/static/audio/*.wav
!backend/static/audio/.gitkeep

# Logs
*.log
logs/

# Frontend
frontend/node_modules/
frontend/dist/
frontend/.vite/
frontend/.env
frontend/.env.local

# Testing
.pytest_cache/
.coverage
htmlcov/

# OS
.DS_Store
Thumbs.db
```

---

## ğŸ¯ LLM Usage Breakdown

### 1. Supervisor LLM (GPT-4o)
**Role:** Strategic decision-making
**Frequency:** Every 20 seconds
**Tasks:**
- Analyze topic scores (votes + weighted reactions)
- Decide: continue current topic or switch?
- If switch: select new topic
- Provide context to Content Generator

**Example Prompt:**
```python
"""
You are the Supervisor AI for an endless podcast.

Current state:
- Current topic: "AI in Healthcare" (3 turns, ğŸ‘ 45, ğŸ‘ 12)
- Top voted topics:
  1. "Future of Work" (votes: 23, ğŸ‘ 89, ğŸ‘ 5)
  2. "Climate Tech" (votes: 15, ğŸ‘ 67, ğŸ‘ 18)

Scoring formula: votes + (ğŸ‘ * 5) + (ğŸ‘ * -3)

Decision needed:
1. Continue current topic? (if ğŸ‘/(ğŸ‘+ğŸ‘) > 0.7)
2. Or switch to top-scored topic?

Output JSON:
{
  "decision": "continue" | "switch",
  "selected_topic": "...",
  "reasoning": "...",
  "context_for_next_turn": "..."
}
"""
```

### 2. Content Generator LLM (GPT-4o-mini)
**Role:** Create engaging dialogue
**Frequency:** Every 20 seconds
**Tasks:**
- Generate Alex's response (2-3 sentences, optimistic)
- Generate Mira's response (2-3 sentences, skeptical)
- Create natural conversation flow
- Provide brief summary

**Example Prompt:**
```python
"""
Generate a podcast dialogue segment.

Topic: {topic}
Turn: {turn_number}
Previous context: {context}

Speakers:
- Alex (optimistic, forward-thinking, enthusiastic)
- Mira (skeptical, pragmatic, analytical)

Alex speaks first (2-3 sentences, max 100 words).
Mira responds (2-3 sentences, max 100 words).

Output JSON:
{
  "alex": "...",
  "mira": "...",
  "summary": "One sentence summary of this exchange"
}
"""
```

### 3. Chat Agent LLMs (3x GPT-4o-mini)
**Role:** Simulate community engagement
**Frequency:** Every 10-15 seconds (staggered)
**Personas:**
- **Enthusiast**: Positive, excited, asks questions
- **Skeptic**: Critical, asks tough questions
- **Curious**: Neutral, seeks clarification

**Example Prompt (Enthusiast):**
```python
"""
You are an AI chat participant persona: "Enthusiast"

Current podcast discussion:
Speaker: Alex
Text: "{current_dialogue}"
Topic: "{topic}"

Generate a short chat comment (10-20 words) that:
- Shows enthusiasm
- References something specific from the dialogue
- Feels human and natural
- Uses casual language

Examples:
- "Wow, great point about the privacy angle!"
- "This is exactly what I've been thinking! ğŸ”¥"
- "Alex makes such a good case here"

Output: Just the comment text.
"""
```

---

## ğŸ”¢ Scoring Algorithm

### Weighted Reaction System

Based on research (Facebook algorithm study), reactions carry more weight than simple votes:

```python
def calculate_topic_score(topic: Topic) -> float:
    """
    Calculate weighted score for topic prioritization.

    Research: Emoji reactions 5x more valuable than likes (Facebook 2017-2019)
    Adapted for podcast voting context.
    """
    base_score = topic.votes * VOTE_WEIGHT  # default: 1
    positive_boost = topic.reactions_thumbs_up * THUMBS_UP_WEIGHT  # default: 5
    negative_penalty = topic.reactions_thumbs_down * abs(THUMBS_DOWN_WEIGHT)  # default: 3

    total_score = base_score + positive_boost - negative_penalty

    # Recency bonus (decay over time)
    age_seconds = time.time() - topic.created_at
    recency_multiplier = max(0.5, 1.0 - (age_seconds / 3600))  # decay over 1 hour

    return total_score * recency_multiplier

def should_continue_topic(current_topic: Topic) -> bool:
    """
    Decide if current topic should continue based on positive reaction ratio.
    """
    total_reactions = current_topic.reactions_thumbs_up + current_topic.reactions_thumbs_down

    if total_reactions < 10:  # Not enough data
        return False

    positive_ratio = current_topic.reactions_thumbs_up / total_reactions

    return positive_ratio >= TOPIC_CONTINUATION_THRESHOLD  # default: 0.7 (70%)
```

---

## ğŸµ Audio Features

### Transition Sounds
Between topic changes, play a 2-3 second audio effect:
- Subtle "whoosh" or musical sting
- Signals topic change to listeners
- Professional podcast feel

### Audio Pipeline
```python
1. Generate dialogue text (Content Generator)
2. Parse into Alex/Mira segments
3. Parallel TTS generation:
   â”œâ”€ OpenAI TTS (Alex, voice=alloy) â†’ alex_123.mp3
   â””â”€ OpenAI TTS (Mira, voice=onyx) â†’ mira_123.mp3
4. Frontend plays sequentially:
   â”œâ”€ Alex audio (auto-play)
   â”œâ”€ Mira audio (queued)
   â””â”€ Update transcript in real-time
```

---

## ğŸš€ Implementation Phases

### Phase 1: Core Backend (2 hours)
- [x] Research & Architecture
- [ ] Professional project structure
- [ ] FastAPI with CORS
- [ ] Pydantic models
- [ ] In-memory state management
- [ ] Basic API endpoints

### Phase 2: LLM Integration (2 hours)
- [ ] Supervisor LLM (topic selection)
- [ ] Content Generator LLM (dialogue)
- [ ] OpenAI TTS (2 voices)
- [ ] Dust API integration (optional enhancement)

### Phase 3: Advanced Features (1.5 hours)
- [ ] Emoji reaction system
- [ ] Weighted scoring algorithm
- [ ] Chat agent personas (3x)
- [ ] Transition sounds
- [ ] Real-time transcription

### Phase 4: Frontend (2 hours)
- [ ] Generate UI in Lovable
- [ ] Export & customize
- [ ] SSE integration
- [ ] Audio player with transcript
- [ ] Community chat UI
- [ ] Nickname modal
- [ ] Reaction buttons

### Phase 5: Polish & Demo (1 hour)
- [ ] Error handling
- [ ] Logging
- [ ] Testing
- [ ] README documentation
- [ ] Record 2-min Loom video

---

## ğŸ“Š Success Metrics

### Must-Have (MVP)
- âœ… Users submit topics with nicknames
- âœ… Emoji reactions (ğŸ‘ğŸ‘) influence topic selection
- âœ… 20-second turn cycle with 2 AI speakers
- âœ… Real-time transcription display
- âœ… AI-generated community chat (3 personas)
- âœ… Transition sounds between topics
- âœ… Uses OpenAI + Dust + Lovable

### Nice-to-Have
- Advanced Dust multi-agent orchestration
- Topic history visualization
- Audio waveform display
- User authentication
- Chat message reactions
- Mobile-responsive design

---

## ğŸ¬ Demo Script (2 minutes)

```
0:00-0:20  Introduction
           - "Endless AI Podcast with community engagement"
           - Show nickname entry modal
           - Explain 3 partner tools: OpenAI, Dust, Lovable

0:20-0:50  User Interaction
           - Submit 3 topics
           - Show voting + ğŸ‘ğŸ‘ reactions
           - Demonstrate weighted scoring
           - AI chat personas commenting

0:50-1:25  Podcast in Action
           - Start podcast
           - Alex speaks (show transcript real-time)
           - Mira responds
           - Transition sound â†’ topic change
           - Show community chat reacting
           - React with ğŸ‘ to extend topic

1:25-1:45  Technical Architecture
           - Show supervisor LLM decision-making
           - Multi-agent architecture diagram
           - Code snippet (scoring algorithm)

1:45-2:00  Conclusion
           - GitHub repo link
           - "Built in one day at Copenhagen AI Hack"
```

---

**Status:** Architecture V2 complete âœ… | Ready to implement ğŸš€
